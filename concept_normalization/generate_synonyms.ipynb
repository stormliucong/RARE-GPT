{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import openai\n",
    "import pandas as pd\n",
    "import logging\n",
    "import random\n",
    "import config\n",
    "import re\n",
    "import time \n",
    "import argparse\n",
    "import json\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "def query_gpt(prompt, gpt_version, test, print_output = False):\n",
    "  logging.debug(f'querying gpt {gpt_version}')\n",
    "  if test:\n",
    "    return prompt + '.test.response'\n",
    "  \n",
    "  openai.api_key = config.OPENAI_API_KEY\n",
    "  completions = openai.ChatCompletion.create( #a method that allows you to generate text-based chatbot responses using a pre-trained GPT language model.\n",
    "      model=gpt_version, \n",
    "      temperature = 0, #controls the level of randomness or creativity in the generated text; . A higher temperature value will result in a more diverse and creative output, as it increases the probability of sampling lower probability tokens. \n",
    "#         max_tokens = 2000, #controls the maximum number of tokens (words or subwords) in the generated text.\n",
    "#         stop = ['###'], #specifies a sequence of tokens that the GPT model should stop generating text when it encounters\n",
    "      n = 1, #the number of possible chat completions or responses that the GPT model should generate in response to a given prompt\n",
    "      messages=[\n",
    "        {'role':'user', 'content': prompt},\n",
    "        ])\n",
    "  # Displaying the output can be helpful if things go wrong\n",
    "  if print_output:\n",
    "      logging.debug(completions)\n",
    "\n",
    "  gpt_response = completions.choices[0]['message']['content']\n",
    "  # Return the first choice's text\n",
    "  return gpt_response"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_hp_synonyms():\n",
    "    # load hpo from json\n",
    "    hpo_json = json.load(open('hp.json'))\n",
    "    synonym_dict_list = []\n",
    "    nodes = hpo_json['graphs'][0]['nodes']\n",
    "    for node in nodes:\n",
    "        # \"id\" : \"http://purl.obolibrary.org/obo/HP_0000016\"\n",
    "        try:\n",
    "            id_component_list = node['id'].split('/')\n",
    "            if 'HP_' in id_component_list[-1]:\n",
    "                synonym_dict = {}\n",
    "                synonym_dict['hp_id'] = id_component_list[-1]\n",
    "                synonym_dict['name'] = node['lbl']\n",
    "                synonyms = node['meta']['synonyms']\n",
    "                synonym_dict['synonyms'] = []\n",
    "                for synonym in synonyms:\n",
    "                    synonym_dict['synonyms'].append(synonym['val'])\n",
    "                synonym_dict_list.append(synonym_dict)\n",
    "        except Exception as e:\n",
    "            pass\n",
    "    return synonym_dict_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "# sample x elements from a list\n",
    "def sample_list(input_list, x):\n",
    "    if len(input_list) > x:\n",
    "        return random.sample(input_list, x)\n",
    "    else:\n",
    "        return input_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:urllib3.connectionpool:Retrying (Retry(total=1, connect=None, read=None, redirect=None, status=None)) after connection broken by 'ProxyError('Cannot connect to proxy.', RemoteDisconnected('Remote end closed connection without response'))': /v1/chat/completions\n"
     ]
    }
   ],
   "source": [
    "synonym_dict_list = load_hp_synonyms()\n",
    "sampled_synonym_dict_list = sample_list(synonym_dict_list, 43)\n",
    "gpt_version = 'gpt-4'\n",
    "print_output = False\n",
    "test = False# load sampled_synonym_dict_list\n",
    "if os.path.exists('sampled_synonym_dict_list_gpt_response.json'):\n",
    "    sampled_synonym_dict_gpt_response_list = json.load(open('sampled_synonym_dict_list_gpt_response.json'))\n",
    "    hp_id_list_with_gpt_response = [sampled_synonym_dict['hp_id'] for sampled_synonym_dict in sampled_synonym_dict_gpt_response_list]\n",
    "else:\n",
    "    sampled_synonym_dict_gpt_response_list = []\n",
    "    hp_id_list_with_gpt_response = []\n",
    "for sampled_synonym_dict in sampled_synonym_dict_list:\n",
    "    if sampled_synonym_dict['hp_id'] in hp_id_list_with_gpt_response:\n",
    "        continue\n",
    "    prompt = f'Please generate five synonyms for the given phenotype term. For example, if the phenotype term is \"Loss of consciousness\", return [\"Fainting\", \"Loss of consciousness\", \"Passing out\"]. Phenotype term: \"{sampled_synonym_dict[\"name\"]}\"'\n",
    "    sampled_synonym_dict['gpt_response'] = query_gpt(prompt, gpt_version, test, print_output = print_output)\n",
    "\n",
    "# combine sampled_synonym_dict_gpt_response_list and sampled_synonym_dict_list\n",
    "sampled_synonym_dict_gpt_response_list.extend(sampled_synonym_dict_list)\n",
    "# output sampled_synonym_dict_list to json\n",
    "json.dump(sampled_synonym_dict_gpt_response_list, open('sampled_synonym_dict_list_gpt_response.json', 'w'), indent=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [],
   "source": [
    "def convert_to_per_synonyms():\n",
    "    synonym_dict_list = []\n",
    "    sampled_synonym_dict_gpt_response_list = json.load(open('sampled_synonym_dict_list_gpt_response.json'))\n",
    "    hp_id_list_with_gpt_response = [sampled_synonym_dict['hp_id'] for sampled_synonym_dict in sampled_synonym_dict_gpt_response_list]\n",
    "    len(hp_id_list_with_gpt_response)\n",
    "    for sampled_synonym_dict in sampled_synonym_dict_gpt_response_list:\n",
    "        hp_id = sampled_synonym_dict['hp_id']\n",
    "        name = sampled_synonym_dict['name']\n",
    "        gpt_response = sampled_synonym_dict['gpt_response']\n",
    "        synonyms = re.findall(r'\"(.*?)\"', gpt_response)\n",
    "        for synonym in synonyms:\n",
    "            if len(synonym) > 3:\n",
    "                synonym_dict_list.append({'synonym': synonym,'name':name, 'hp_id': hp_id})\n",
    "    \n",
    "    synonym_df = pd.DataFrame(synonym_dict_list)\n",
    "    synonym_df.to_csv('synonym_df.csv', index = False)\n",
    "    return synonym_df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [],
   "source": [
    "synonym_df = convert_to_per_synonyms()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".openai",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
