{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tqdm import tqdm\n",
    "from whoosh import scoring\n",
    "from whoosh.index import create_in, open_dir\n",
    "from whoosh.fields import Schema, TEXT, ID\n",
    "from whoosh.analysis import StemmingAnalyzer\n",
    "from whoosh.index import open_dir\n",
    "from whoosh.qparser import QueryParser, OrGroup, AndGroup\n",
    "import os\n",
    "import json\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_hp_synonyms():\n",
    "    # load hpo from json\n",
    "    hpo_json = json.load(open('hp.json'))\n",
    "    synonym_dict_list = []\n",
    "    nodes = hpo_json['graphs'][0]['nodes']\n",
    "    for node in nodes:\n",
    "        # \"id\" : \"http://purl.obolibrary.org/obo/HP_0000016\"\n",
    "        try:\n",
    "            id_component_list = node['id'].split('/')\n",
    "            if 'HP_' in id_component_list[-1]:\n",
    "                synonym_dict = {}\n",
    "                synonym_dict['hp_id'] = id_component_list[-1]\n",
    "                synonym_dict['name'] = node['lbl']\n",
    "                synonyms = node['meta']['synonyms']\n",
    "                synonym_dict['synonyms'] = []\n",
    "                for synonym in synonyms:\n",
    "                    synonym_dict['synonyms'].append(synonym['val'])\n",
    "                synonym_dict_list.append(synonym_dict)\n",
    "        except Exception as e:\n",
    "            pass\n",
    "    return synonym_dict_list\n",
    "\n",
    "def create_index(index_dir, synonym_dict_list):\n",
    "    # Create an index and schema\n",
    "    stem_ana = StemmingAnalyzer()\n",
    "    custom_schema = Schema(hp_id=ID(stored=True),\n",
    "                hp_desc=TEXT(stored=True, analyzer=stem_ana),\n",
    "    )\n",
    "    # create if not exist\n",
    "    if not os.path.exists(index_dir):\n",
    "        os.mkdir(index_dir)\n",
    "    else:\n",
    "        # delete forecely and recreate\n",
    "        import shutil\n",
    "        shutil.rmtree(index_dir)\n",
    "        os.mkdir(index_dir)\n",
    "    index = create_in(index_dir, custom_schema)\n",
    "\n",
    "    # Open the index\n",
    "    index = open_dir(index_dir)\n",
    "\n",
    "    # Create a writer to add documents to the index\n",
    "    writer = index.writer()\n",
    "\n",
    "    # Add documents to the index\n",
    "    for i in tqdm(range(len(synonym_dict_list))):\n",
    "        phrase = synonym_dict_list[i]\n",
    "        synonyms = phrase['synonyms']\n",
    "        synonyms.extend([phrase['name']])\n",
    "        for synonym in synonyms:\n",
    "            writer.add_document(hp_id=str(phrase['hp_id']),\n",
    "                                hp_desc=synonym\n",
    "                                )\n",
    "    writer.commit()\n",
    "    return 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "def query_terms(index_dir, query_name_list, output, top_k=1):\n",
    "    def custom_scoring(searcher, fieldname, text, matcher):\n",
    "        frequency = scoring.Frequency().scorer(searcher, fieldname, text).score(matcher)\n",
    "        tfidf =  scoring.TF_IDF().scorer(searcher, fieldname, text).score(matcher)\n",
    "        bm25 = scoring.BM25F().scorer(searcher, fieldname, text).score(matcher)\n",
    "        return frequency + tfidf + bm25\n",
    "    \n",
    "    query_results = []\n",
    "    index = open_dir(index_dir)\n",
    "    my_weighting = scoring.FunctionWeighting(custom_scoring)\n",
    "    # scoring.BM25F(B=10, K1=0.1)\n",
    "    searcher = index.searcher(weighting=scoring.BM25F(B=10, K1=0.1))\n",
    "    query_parser = QueryParser('hp_desc', schema=index.schema, group=OrGroup)\n",
    "    # Tokenize the query text using the same analyzer\n",
    "    for query_name in tqdm(query_name_list):\n",
    "        query = query_parser.parse('{}'.format(query_name))\n",
    "        results = searcher.search(query, limit=10, scored=True)\n",
    "        # Retrieve the top k matching phrase\n",
    "        if len(results) > 0:\n",
    "            # Retrieve and print the ranked matching phrases\n",
    "            # top k only\n",
    "            results = results[:top_k]\n",
    "            for i, result in enumerate(results):\n",
    "                hp_desc = result['hp_desc']\n",
    "                hp_id = result['hp_id']\n",
    "                score = result.score\n",
    "                query_results.append({'query_name': query_name, 'hp_desc': hp_desc, 'hp_id': hp_id, 'score': score})\n",
    "        else:\n",
    "            query_results.append({'query_name': query_name, 'hp_desc': '', 'hp_id': '', 'score': -1})\n",
    "    searcher.close()\n",
    "    query_results_df = pd.DataFrame(query_results)\n",
    "    query_results_df.to_csv(output, index=False)   \n",
    "    return query_results_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 10445/10445 [00:03<00:00, 2968.11it/s]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "synonym_dict_list = load_hp_synonyms()\n",
    "index_dir = './woosh_index'\n",
    "create_index(index_dir, synonym_dict_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/498 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/498 [00:00<?, ?it/s]\n"
     ]
    },
    {
     "ename": "NotImplementedError",
     "evalue": "FunctionScorer",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNotImplementedError\u001b[0m                       Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[19], line 3\u001b[0m\n\u001b[1;32m      1\u001b[0m query_name_list \u001b[38;5;241m=\u001b[39m pd\u001b[38;5;241m.\u001b[39mread_csv(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124msynonym_df.csv\u001b[39m\u001b[38;5;124m'\u001b[39m)[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124msynonym\u001b[39m\u001b[38;5;124m'\u001b[39m]\u001b[38;5;241m.\u001b[39mtolist()\n\u001b[1;32m      2\u001b[0m output \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124m./woosh_query_results.csv\u001b[39m\u001b[38;5;124m'\u001b[39m\n\u001b[0;32m----> 3\u001b[0m \u001b[43mquery_terms\u001b[49m\u001b[43m(\u001b[49m\u001b[43mindex_dir\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mquery_name_list\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43moutput\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtop_k\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m)\u001b[49m\n",
      "Cell \u001b[0;32mIn[18], line 17\u001b[0m, in \u001b[0;36mquery_terms\u001b[0;34m(index_dir, query_name_list, output, top_k)\u001b[0m\n\u001b[1;32m     15\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m query_name \u001b[38;5;129;01min\u001b[39;00m tqdm(query_name_list):\n\u001b[1;32m     16\u001b[0m     query \u001b[38;5;241m=\u001b[39m query_parser\u001b[38;5;241m.\u001b[39mparse(\u001b[38;5;124m'\u001b[39m\u001b[38;5;132;01m{}\u001b[39;00m\u001b[38;5;124m'\u001b[39m\u001b[38;5;241m.\u001b[39mformat(query_name))\n\u001b[0;32m---> 17\u001b[0m     results \u001b[38;5;241m=\u001b[39m \u001b[43msearcher\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msearch\u001b[49m\u001b[43m(\u001b[49m\u001b[43mquery\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlimit\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m10\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mscored\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m)\u001b[49m\n\u001b[1;32m     18\u001b[0m     \u001b[38;5;66;03m# Retrieve the top k matching phrase\u001b[39;00m\n\u001b[1;32m     19\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(results) \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m0\u001b[39m:\n\u001b[1;32m     20\u001b[0m         \u001b[38;5;66;03m# Retrieve and print the ranked matching phrases\u001b[39;00m\n\u001b[1;32m     21\u001b[0m         \u001b[38;5;66;03m# top k only\u001b[39;00m\n",
      "File \u001b[0;32m/phi_home/cl3720/phi/RESCUE/RARE-GPT/.openai/lib/python3.10/site-packages/whoosh/searching.py:786\u001b[0m, in \u001b[0;36mSearcher.search\u001b[0;34m(self, q, **kwargs)\u001b[0m\n\u001b[1;32m    784\u001b[0m c \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcollector(\u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[1;32m    785\u001b[0m \u001b[38;5;66;03m# Call the lower-level method to run the collector\u001b[39;00m\n\u001b[0;32m--> 786\u001b[0m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msearch_with_collector\u001b[49m\u001b[43m(\u001b[49m\u001b[43mq\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mc\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    787\u001b[0m \u001b[38;5;66;03m# Return the results object from the collector\u001b[39;00m\n\u001b[1;32m    788\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m c\u001b[38;5;241m.\u001b[39mresults()\n",
      "File \u001b[0;32m/phi_home/cl3720/phi/RESCUE/RARE-GPT/.openai/lib/python3.10/site-packages/whoosh/searching.py:819\u001b[0m, in \u001b[0;36mSearcher.search_with_collector\u001b[0;34m(self, q, collector, context)\u001b[0m\n\u001b[1;32m    816\u001b[0m \u001b[38;5;66;03m# Allow collector to set up based on the top-level information\u001b[39;00m\n\u001b[1;32m    817\u001b[0m collector\u001b[38;5;241m.\u001b[39mprepare(\u001b[38;5;28mself\u001b[39m, q, context)\n\u001b[0;32m--> 819\u001b[0m \u001b[43mcollector\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrun\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/phi_home/cl3720/phi/RESCUE/RARE-GPT/.openai/lib/python3.10/site-packages/whoosh/collectors.py:144\u001b[0m, in \u001b[0;36mCollector.run\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    142\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m subsearcher, offset \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtop_searcher\u001b[38;5;241m.\u001b[39mleaf_searchers():\n\u001b[1;32m    143\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mset_subsearcher(subsearcher, offset)\n\u001b[0;32m--> 144\u001b[0m         \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcollect_matches\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    145\u001b[0m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[1;32m    146\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mfinish()\n",
      "File \u001b[0;32m/phi_home/cl3720/phi/RESCUE/RARE-GPT/.openai/lib/python3.10/site-packages/whoosh/collectors.py:214\u001b[0m, in \u001b[0;36mCollector.collect_matches\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    206\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"This method calls :meth:`Collector.matches` and then for each\u001b[39;00m\n\u001b[1;32m    207\u001b[0m \u001b[38;5;124;03mmatched document calls :meth:`Collector.collect`. Sub-classes that\u001b[39;00m\n\u001b[1;32m    208\u001b[0m \u001b[38;5;124;03mwant to intervene between finding matches and adding them to the\u001b[39;00m\n\u001b[1;32m    209\u001b[0m \u001b[38;5;124;03mcollection (for example, to filter out certain documents) can override\u001b[39;00m\n\u001b[1;32m    210\u001b[0m \u001b[38;5;124;03mthis method.\u001b[39;00m\n\u001b[1;32m    211\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m    213\u001b[0m collect \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcollect\n\u001b[0;32m--> 214\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m sub_docnum \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmatches():\n\u001b[1;32m    215\u001b[0m     collect(sub_docnum)\n",
      "File \u001b[0;32m/phi_home/cl3720/phi/RESCUE/RARE-GPT/.openai/lib/python3.10/site-packages/whoosh/collectors.py:392\u001b[0m, in \u001b[0;36mScoredCollector.matches\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    390\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m replace:\n\u001b[1;32m    391\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m replacecounter \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m0\u001b[39m \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mminscore \u001b[38;5;241m!=\u001b[39m minscore:\n\u001b[0;32m--> 392\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmatcher \u001b[38;5;241m=\u001b[39m matcher \u001b[38;5;241m=\u001b[39m \u001b[43mmatcher\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mreplace\u001b[49m\u001b[43m(\u001b[49m\u001b[43mminscore\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01mor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m    393\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mreplaced_times \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m\n\u001b[1;32m    394\u001b[0m         \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m matcher\u001b[38;5;241m.\u001b[39mis_active():\n",
      "File \u001b[0;32m/phi_home/cl3720/phi/RESCUE/RARE-GPT/.openai/lib/python3.10/site-packages/whoosh/matching/binary.py:133\u001b[0m, in \u001b[0;36mUnionMatcher.replace\u001b[0;34m(self, minquality)\u001b[0m\n\u001b[1;32m    130\u001b[0m \u001b[38;5;66;03m# If neither sub-matcher on its own has a high enough max quality to\u001b[39;00m\n\u001b[1;32m    131\u001b[0m \u001b[38;5;66;03m# contribute, convert to an intersection matcher\u001b[39;00m\n\u001b[1;32m    132\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m minquality \u001b[38;5;129;01mand\u001b[39;00m a_active \u001b[38;5;129;01mand\u001b[39;00m b_active:\n\u001b[0;32m--> 133\u001b[0m     a_max \u001b[38;5;241m=\u001b[39m \u001b[43ma\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmax_quality\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    134\u001b[0m     b_max \u001b[38;5;241m=\u001b[39m b\u001b[38;5;241m.\u001b[39mmax_quality()\n\u001b[1;32m    135\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m a_max \u001b[38;5;241m<\u001b[39m minquality \u001b[38;5;129;01mand\u001b[39;00m b_max \u001b[38;5;241m<\u001b[39m minquality:\n",
      "File \u001b[0;32m/phi_home/cl3720/phi/RESCUE/RARE-GPT/.openai/lib/python3.10/site-packages/whoosh/matching/mcore.py:616\u001b[0m, in \u001b[0;36mLeafMatcher.max_quality\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    615\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mmax_quality\u001b[39m(\u001b[38;5;28mself\u001b[39m):\n\u001b[0;32m--> 616\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mscorer\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmax_quality\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/phi_home/cl3720/phi/RESCUE/RARE-GPT/.openai/lib/python3.10/site-packages/whoosh/scoring.py:119\u001b[0m, in \u001b[0;36mBaseScorer.max_quality\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    112\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mmax_quality\u001b[39m(\u001b[38;5;28mself\u001b[39m):\n\u001b[1;32m    113\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"Returns the *maximum limit* on the possible score the matcher can\u001b[39;00m\n\u001b[1;32m    114\u001b[0m \u001b[38;5;124;03m    give. This can be an estimate and not necessarily the actual maximum\u001b[39;00m\n\u001b[1;32m    115\u001b[0m \u001b[38;5;124;03m    score possible, but it must never be less than the actual maximum\u001b[39;00m\n\u001b[1;32m    116\u001b[0m \u001b[38;5;124;03m    score.\u001b[39;00m\n\u001b[1;32m    117\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[0;32m--> 119\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mNotImplementedError\u001b[39;00m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__class__\u001b[39m\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__name__\u001b[39m)\n",
      "\u001b[0;31mNotImplementedError\u001b[0m: FunctionScorer"
     ]
    }
   ],
   "source": [
    "query_name_list = pd.read_csv('synonym_df.csv')['synonym'].tolist()\n",
    "output = './woosh_query_results.csv'\n",
    "query_terms(index_dir, query_name_list, output, top_k=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".openai",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
